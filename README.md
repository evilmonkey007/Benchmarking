# Benchmarking
This project aims to benchmark the performance of various algorithms on the Sentiment Analysis task described [here](http://www.aclweb.org/anthology/P/P04/P04-1035.pdf?CFID=2). It looks at their performance on the following datasets: 
* [Cornell Sentence Polarity Dataset](http://www.cs.cornell.edu/people/pabo/movie-review-data/): Referred to as the Rotten Tomatoes or RT dataset.
* [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/): Referred to as the IMDB dataset.
* [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/treebank.html): Referred to as the SST dataset. The fine-grained version of the dataset is referred to as SST1 whereas the binary dataset is referred to as SST2. 
* [Cornell Subjectivity Dataset](http://www.cs.cornell.edu/people/pabo/movie-review-data/): Referred to as the SUBJ dataset.

Currently only an LSTM based model has been implemented.

## Dependencies
This project has been written for Python 2.7. It uses the Lasagne, Theano and Numpy libraries.

## To Run 
`python runModel.py`

### This project is ongoing.
